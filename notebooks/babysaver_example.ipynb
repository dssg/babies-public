{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the babysaver module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an introduction to the `babysaver` module written by Team Babies as part of DSSG 2015 for our project with the Illinois Department of Human Services (IDHS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, we're going to need to establish a connection with our PostgreSQL server and insert into our system path the location of our `babysaver` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "\n",
    "with open('/mnt/data/predicting-adverse-births/passwords/psql_psycopg2.password', 'r') as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**params)\n",
    "    conn.autocommit\n",
    "    cur = conn.cursor()\n",
    "\n",
    "except:\n",
    "    print('Unable to connect to database')\n",
    "\n",
    "with open('/mnt/data/predicting-adverse-births/passwords/psql_engine.password', 'r') as f:\n",
    "    engine = create_engine(f.read())\n",
    "\n",
    "babysaver_parent = '/mnt/data/predicting-adverse-births/babies/' # clone the babies repo\n",
    "import sys\n",
    "sys.path.insert(0, babysaver_parent)\n",
    "from babysaver import features\n",
    "from babysaver import models\n",
    "from babysaver.models import WeightedQuestions\n",
    "from babysaver import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "The next step is to gather our data. We have a data configuration file that allows you to specify which questions from which assessment during which time frame from which populations in addition to which additional features and which outcome you would like to extract from our database. We also have a `config_writer()` function that allows you to write a dictionary of values to a config file to avoid entering values in a spreadsheet. The `data_getter()` function also has the option to create all two-way interaction terms and carry out basic imputation strategies (such as impute all missing question values with 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_getter: there are no continuous values to standardize\n",
      "data_getter: dataset has dimensions (6457, 22)\n"
     ]
    }
   ],
   "source": [
    "config_add1 = {\n",
    "               'Features': None, \n",
    "               'Include 707G?': 'Y', \n",
    "               '707G Questions': range(35,52), \n",
    "               '707G Start Date': '2014-07-01', \n",
    "               '707G End Date': None,\n",
    "               'Include 711?': 'N', \n",
    "               '711 Questions': [], \n",
    "               '711 Start Date': None, \n",
    "               '711 End Date': None, \n",
    "               'Include FCM?': 'Y',  \n",
    "               'Include BBO?': 'Y', \n",
    "               'Include other?': 'Y', \n",
    "               'Outcome': 'ADVB1_OTC'\n",
    "              }\n",
    "\n",
    "features.config_writer(config_add1, '/home/ipan/configs/config_add1.csv')\n",
    "data_dct = features.data_getter('/home/ipan/configs/config_add1.csv', \n",
    "                                conn=conn, \n",
    "                                unique_identifier='UNI_PART_ID_I',  \n",
    "                                impute='fill_mode',\n",
    "                                interactions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`data_getter()` returns a dictionary that includes the resulting dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also contains the path to the config file used to generate the dataset, as well as the list of features, the outcome, the unique identifier column, holdout dataset if specified and the date column (deprecated). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config_file',\n",
       " 'features',\n",
       " 'dataframe',\n",
       " 'date',\n",
       " 'holdout',\n",
       " 'outcome',\n",
       " 'unique_id']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dct.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the models\n",
    "\n",
    "Now that we have our data we can start training classifiers. We need to import classifiers from `sklearn` and then specify dictionaries for each classifier family including a dictionary of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "logit_lib = {'clf': LogisticRegression,\n",
    "             'param_dict': {'C': [1e-4, 1e-3, 0.01, 0.1, 1, 10, 1e3, 1e4, 1e20],\n",
    "                            'penalty': ['l1', 'l2'],\n",
    "                            'class_weight': [None, 'auto']\n",
    "                           }\n",
    "             }\n",
    "\n",
    "rf_lib = {'clf': RandomForestClassifier,\n",
    "          'param_dict': {'n_estimators': [100],\n",
    "                         'max_depth': [None, 2, 5, 10, 20, 50],\n",
    "                         'max_features': [None, 'sqrt', 'log2'],\n",
    "                         'min_samples_split': [2, 5, 10],\n",
    "                         'n_jobs': [-1],\n",
    "                         'criterion': ['entropy', 'gini']\n",
    "                        }\n",
    "          }\n",
    "\n",
    "adaboost_lib = {'clf': AdaBoostClassifier,\n",
    "                'param_dict': {'n_estimators': [100],\n",
    "                              'learning_rate': [0.1, 0.5, 1, 2, 5]\n",
    "                              }\n",
    "                }\n",
    "\n",
    "gnb_lib = {'clf': GaussianNB,\n",
    "           'param_dict': {}\n",
    "          }\n",
    "\n",
    "bnb_lib = {'clf': BernoulliNB,\n",
    "           'param_dict': {}\n",
    "          }\n",
    "\n",
    "lda_lib = {'clf': LDA,\n",
    "           'param_dict': {}\n",
    "          }\n",
    "\n",
    "qda_lib = {'clf': QDA,\n",
    "           'param_dict': {}\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can pass a list of these libraries and the `data_dct` from `data_getter()` to the `machine_learner()` function to start training our classifiers. We can also specify whether we want to print evaluation sheets (`make_evals=True`) but this will increase the runtime. Models will be pickled in the specified directory (or `./pickles/` by default -- note that if you do not specify the folder it will prompt you to confirm the folder, so if you want to run this through an automated script you should specify a different folder name). There are different cross-validation schemes as well but `kfold_cv` is the only one that has been fully tested. This function will return a dictionary of dataframes, each of which is a list of metrics for each classifier, as well as a dictionary for the pickle file name of each classifier. See `help(models.machine_learner)` for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.320212\n",
      "\n",
      "Running LogisticRegression(C=0.0001, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.320910\n",
      "\n",
      "Running LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.328651\n",
      "\n",
      "Running LogisticRegression(C=0.001, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.316168\n",
      "\n",
      "Running LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.330891\n",
      "\n",
      "Running LogisticRegression(C=0.01, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.318869\n",
      "\n",
      "Running LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.382091\n",
      "\n",
      "Running LogisticRegression(C=0.1, class_weight='auto', dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.382712\n",
      "\n",
      "Running LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.396965\n",
      "\n",
      "Running LogisticRegression(C=1, class_weight='auto', dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.402331\n",
      "\n",
      "Running LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.402694\n",
      "\n",
      "Running LogisticRegression(C=10, class_weight='auto', dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.401536\n",
      "\n",
      "Running LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.402182\n",
      "\n",
      "Running LogisticRegression(C=1000.0, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.400726\n",
      "\n",
      "Running LogisticRegression(C=10000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.399456\n",
      "\n",
      "Running LogisticRegression(C=10000.0, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.404000\n",
      "\n",
      "Running LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.403667\n",
      "\n",
      "Running LogisticRegression(C=1e+20, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.402328\n",
      "\n",
      "Running LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.364524\n",
      "\n",
      "Running LogisticRegression(C=0.0001, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.381151\n",
      "\n",
      "Running LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.379761\n",
      "\n",
      "Running LogisticRegression(C=0.001, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.376176\n",
      "\n",
      "Running LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.391615\n",
      "\n",
      "Running LogisticRegression(C=0.01, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.434814\n",
      "\n",
      "Running LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.406865\n",
      "\n",
      "Running LogisticRegression(C=0.1, class_weight='auto', dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.414197\n",
      "\n",
      "Running LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.426004\n",
      "\n",
      "Running LogisticRegression(C=1, class_weight='auto', dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.430902\n",
      "\n",
      "Running LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.426705\n",
      "\n",
      "Running LogisticRegression(C=10, class_weight='auto', dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.432601\n",
      "\n",
      "Running LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.421830\n",
      "\n",
      "Running LogisticRegression(C=1000.0, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.432508\n",
      "\n",
      "Running LogisticRegression(C=10000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.422352\n",
      "\n",
      "Running LogisticRegression(C=10000.0, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.444862\n",
      "\n",
      "Running LogisticRegression(C=1e+20, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.420858\n",
      "\n",
      "Running LogisticRegression(C=1e+20, class_weight='auto', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0)\n",
      "...\n",
      "Finished in: 0:00:00.437257\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.306707\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.533452\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.001351\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.822077\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=20, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.129220\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=50, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.495920\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.030545\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=2, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.863402\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.906797\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.898788\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.183787\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.024716\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.062133\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=2, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.826304\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.919846\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=10, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.937089\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=20, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.170421\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=50, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.247641\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.081492\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.878534\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.062954\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.838082\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.025704\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.149634\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.116550\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.656106\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.865192\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.839699\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.079139\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.076720\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.091777\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.560966\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.870882\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.927998\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.063943\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.078795\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.209857\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.535220\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.005319\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.833844\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=20, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.315878\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=50, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.364685\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.029695\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=2, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.659135\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.884351\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.851791\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.072281\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.034257\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.061289\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=2, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.781985\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.910828\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=10, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.042829\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=20, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.022270\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=50, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.021346\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.005198\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.772041\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.961416\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.824478\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.195120\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.972312\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.010753\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.886135\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.939969\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.856663\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.002592\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.066369\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.102459\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.839102\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.844212\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.896800\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.012214\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.070955\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.271440\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.827547\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.956711\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.861525\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=20, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.919479\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=50, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.378601\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.028166\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=2, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.767604\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.053902\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.932311\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.036924\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.017551\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.099946\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=2, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.774105\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.863050\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=10, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.826703\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=20, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.002088\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=50, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.967269\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.715545\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.824188\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.953321\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.730658\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.949908\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features=None, max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.186746\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.974667\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.661516\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.867236\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.951479\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.071011\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.080103\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.983088\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.570611\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.825060\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.904813\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:05.941646\n",
      "\n",
      "Running RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features='log2', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "...\n",
      "Finished in: 0:00:06.138915\n",
      "\n",
      "Running AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.1, n_estimators=100, random_state=None)\n",
      "...\n",
      "Finished in: 0:00:05.195547\n",
      "\n",
      "Running AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.5, n_estimators=100, random_state=None)\n",
      "...\n",
      "Finished in: 0:00:05.194237\n",
      "\n",
      "Running AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
      "          n_estimators=100, random_state=None)\n",
      "...\n",
      "Finished in: 0:00:05.351599\n",
      "\n",
      "Running AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=2,\n",
      "          n_estimators=100, random_state=None)\n",
      "...\n",
      "Finished in: 0:00:05.182008\n",
      "\n",
      "Running AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=5,\n",
      "          n_estimators=100, random_state=None)\n",
      "...\n",
      "Finished in: 0:00:04.435360\n",
      "\n",
      "Running GaussianNB()\n",
      "...\n",
      "Finished in: 0:00:00.362537\n",
      "\n",
      "Running BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "...\n",
      "Finished in: 0:00:00.370889\n",
      "\n",
      "Running LDA(n_components=None, priors=None, shrinkage=None, solver='svd',\n",
      "  store_covariance=False, tol=0.0001)\n",
      "...\n",
      "Finished in: 0:00:00.401709\n",
      "\n",
      "Running QDA(priors=None, reg_param=0.0)\n",
      "...\n",
      "Finished in: 0:00:00.408922\n",
      "\n",
      "machine_learner: finished running models\n",
      "machine_learner: pickle files available in yay_pkls/\n",
      "machine_learner: total runtime was 0:11:25.637773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "eval_dct, pkl_dct = models.machine_learner(data_dct, clf_library=[logit_lib, rf_lib, adaboost_lib, \n",
    "                                                                  gnb_lib, bnb_lib, lda_lib, qda_lib],\n",
    "                                           cv='kfold_cv', verbose=True, n_folds=10, pkl_folder='yay_pkls',\n",
    "                                           k=[0.05, 0.1, 0.15, 0.2, 0.25, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the models\n",
    "\n",
    "There's not much we can do with a dictionary of dataframes if we want to analyze all of the classifiers at the same time. We can use `dict_to_dataframe` to create a one dataframe containing the metrics and pickle file names for each classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_prec_score_mean</th>\n",
       "      <th>avg_prec_score_std</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>roc_auc_std</th>\n",
       "      <th>avg_prec_0.05 mean</th>\n",
       "      <th>avg_prec_0.05 std</th>\n",
       "      <th>precision at 0.05 mean</th>\n",
       "      <th>precision at 0.05 std</th>\n",
       "      <th>recall at 0.05 mean</th>\n",
       "      <th>recall at 0.05 std</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_prec_0.3 std</th>\n",
       "      <th>precision at 0.3 mean</th>\n",
       "      <th>precision at 0.3 std</th>\n",
       "      <th>recall at 0.3 mean</th>\n",
       "      <th>recall at 0.3 std</th>\n",
       "      <th>test_count at 0.3 mean</th>\n",
       "      <th>test_count at 0.3 std</th>\n",
       "      <th>test_percent at 0.3 mean</th>\n",
       "      <th>test_percent at 0.3 std</th>\n",
       "      <th>pickle_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_features=None, max_leaf_nodes=None,\\n            min_samples_leaf=1, min_samples_split=10,\\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\\n            oob_score=False, random_state=None, verbose=0,\\n            warm_start=False)</th>\n",
       "      <td>0.227689</td>\n",
       "      <td>0.037991</td>\n",
       "      <td>0.564351</td>\n",
       "      <td>0.035016</td>\n",
       "      <td>0.042793</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.280492</td>\n",
       "      <td>0.096231</td>\n",
       "      <td>0.092683</td>\n",
       "      <td>0.033848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038559</td>\n",
       "      <td>0.215661</td>\n",
       "      <td>0.030034</td>\n",
       "      <td>0.421209</td>\n",
       "      <td>0.052806</td>\n",
       "      <td>205.5</td>\n",
       "      <td>16.641648</td>\n",
       "      <td>0.318261</td>\n",
       "      <td>0.025804</td>\n",
       "      <td>yay_pkls/RandomForestClassifier126.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=None, max_features='log2', max_leaf_nodes=None,\\n            min_samples_leaf=1, min_samples_split=5,\\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\\n            oob_score=False, random_state=None, verbose=0,\\n            warm_start=False)</th>\n",
       "      <td>0.228491</td>\n",
       "      <td>0.036778</td>\n",
       "      <td>0.563230</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>0.046269</td>\n",
       "      <td>0.030128</td>\n",
       "      <td>0.301346</td>\n",
       "      <td>0.128485</td>\n",
       "      <td>0.083150</td>\n",
       "      <td>0.034220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037046</td>\n",
       "      <td>0.211890</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.435476</td>\n",
       "      <td>0.069877</td>\n",
       "      <td>215.5</td>\n",
       "      <td>24.636242</td>\n",
       "      <td>0.333738</td>\n",
       "      <td>0.038073</td>\n",
       "      <td>yay_pkls/RandomForestClassifier102.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=5,\\n          n_estimators=100, random_state=None)</th>\n",
       "      <td>0.349449</td>\n",
       "      <td>0.121060</td>\n",
       "      <td>0.634610</td>\n",
       "      <td>0.085664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>yay_pkls/AdaBoostClassifier148.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression(C=10, class_weight='auto', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr',\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0)</th>\n",
       "      <td>0.269039</td>\n",
       "      <td>0.036457</td>\n",
       "      <td>0.594393</td>\n",
       "      <td>0.032791</td>\n",
       "      <td>0.071361</td>\n",
       "      <td>0.032236</td>\n",
       "      <td>0.381378</td>\n",
       "      <td>0.097234</td>\n",
       "      <td>0.120357</td>\n",
       "      <td>0.033885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040510</td>\n",
       "      <td>0.226779</td>\n",
       "      <td>0.023373</td>\n",
       "      <td>0.430751</td>\n",
       "      <td>0.063380</td>\n",
       "      <td>198.6</td>\n",
       "      <td>16.153431</td>\n",
       "      <td>0.307571</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>yay_pkls/LogisticRegression29.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\\n            max_depth=50, max_features='log2', max_leaf_nodes=None,\\n            min_samples_leaf=1, min_samples_split=5,\\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\\n            oob_score=False, random_state=None, verbose=0,\\n            warm_start=False)</th>\n",
       "      <td>0.226853</td>\n",
       "      <td>0.034828</td>\n",
       "      <td>0.563092</td>\n",
       "      <td>0.036765</td>\n",
       "      <td>0.045904</td>\n",
       "      <td>0.027237</td>\n",
       "      <td>0.306021</td>\n",
       "      <td>0.124561</td>\n",
       "      <td>0.085998</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033072</td>\n",
       "      <td>0.211291</td>\n",
       "      <td>0.027636</td>\n",
       "      <td>0.435485</td>\n",
       "      <td>0.078397</td>\n",
       "      <td>215.8</td>\n",
       "      <td>24.956852</td>\n",
       "      <td>0.334204</td>\n",
       "      <td>0.038582</td>\n",
       "      <td>yay_pkls/RandomForestClassifier107.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    avg_prec_score_mean  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...             0.227689   \n",
       "RandomForestClassifier(bootstrap=True, class_we...             0.228491   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...             0.349449   \n",
       "LogisticRegression(C=10, class_weight='auto', d...             0.269039   \n",
       "RandomForestClassifier(bootstrap=True, class_we...             0.226853   \n",
       "\n",
       "                                                    avg_prec_score_std  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.037991   \n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.036778   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...            0.121060   \n",
       "LogisticRegression(C=10, class_weight='auto', d...            0.036457   \n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.034828   \n",
       "\n",
       "                                                    roc_auc_mean  roc_auc_std  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...      0.564351     0.035016   \n",
       "RandomForestClassifier(bootstrap=True, class_we...      0.563230     0.036368   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...      0.634610     0.085664   \n",
       "LogisticRegression(C=10, class_weight='auto', d...      0.594393     0.032791   \n",
       "RandomForestClassifier(bootstrap=True, class_we...      0.563092     0.036765   \n",
       "\n",
       "                                                    avg_prec_0.05 mean  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.042793   \n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.046269   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...            0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...            0.071361   \n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.045904   \n",
       "\n",
       "                                                    avg_prec_0.05 std  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...           0.026549   \n",
       "RandomForestClassifier(bootstrap=True, class_we...           0.030128   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...           0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...           0.032236   \n",
       "RandomForestClassifier(bootstrap=True, class_we...           0.027237   \n",
       "\n",
       "                                                    precision at 0.05 mean  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...                0.280492   \n",
       "RandomForestClassifier(bootstrap=True, class_we...                0.301346   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...                0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...                0.381378   \n",
       "RandomForestClassifier(bootstrap=True, class_we...                0.306021   \n",
       "\n",
       "                                                    precision at 0.05 std  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...               0.096231   \n",
       "RandomForestClassifier(bootstrap=True, class_we...               0.128485   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...               0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...               0.097234   \n",
       "RandomForestClassifier(bootstrap=True, class_we...               0.124561   \n",
       "\n",
       "                                                    recall at 0.05 mean  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...             0.092683   \n",
       "RandomForestClassifier(bootstrap=True, class_we...             0.083150   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...             0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...             0.120357   \n",
       "RandomForestClassifier(bootstrap=True, class_we...             0.085998   \n",
       "\n",
       "                                                    recall at 0.05 std  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.033848   \n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.034220   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...            0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...            0.033885   \n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.034483   \n",
       "\n",
       "                                                                     ...                    \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...                   ...                     \n",
       "RandomForestClassifier(bootstrap=True, class_we...                   ...                     \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...                   ...                     \n",
       "LogisticRegression(C=10, class_weight='auto', d...                   ...                     \n",
       "RandomForestClassifier(bootstrap=True, class_we...                   ...                     \n",
       "\n",
       "                                                    avg_prec_0.3 std  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...          0.038559   \n",
       "RandomForestClassifier(bootstrap=True, class_we...          0.037046   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...          0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...          0.040510   \n",
       "RandomForestClassifier(bootstrap=True, class_we...          0.033072   \n",
       "\n",
       "                                                    precision at 0.3 mean  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...               0.215661   \n",
       "RandomForestClassifier(bootstrap=True, class_we...               0.211890   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...               0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...               0.226779   \n",
       "RandomForestClassifier(bootstrap=True, class_we...               0.211291   \n",
       "\n",
       "                                                    precision at 0.3 std  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...              0.030034   \n",
       "RandomForestClassifier(bootstrap=True, class_we...              0.024902   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...              0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...              0.023373   \n",
       "RandomForestClassifier(bootstrap=True, class_we...              0.027636   \n",
       "\n",
       "                                                    recall at 0.3 mean  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.421209   \n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.435476   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...            0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...            0.430751   \n",
       "RandomForestClassifier(bootstrap=True, class_we...            0.435485   \n",
       "\n",
       "                                                    recall at 0.3 std  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...           0.052806   \n",
       "RandomForestClassifier(bootstrap=True, class_we...           0.069877   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...           0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...           0.063380   \n",
       "RandomForestClassifier(bootstrap=True, class_we...           0.078397   \n",
       "\n",
       "                                                    test_count at 0.3 mean  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...                   205.5   \n",
       "RandomForestClassifier(bootstrap=True, class_we...                   215.5   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...                     0.0   \n",
       "LogisticRegression(C=10, class_weight='auto', d...                   198.6   \n",
       "RandomForestClassifier(bootstrap=True, class_we...                   215.8   \n",
       "\n",
       "                                                    test_count at 0.3 std  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...              16.641648   \n",
       "RandomForestClassifier(bootstrap=True, class_we...              24.636242   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...               0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...              16.153431   \n",
       "RandomForestClassifier(bootstrap=True, class_we...              24.956852   \n",
       "\n",
       "                                                    test_percent at 0.3 mean  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...                  0.318261   \n",
       "RandomForestClassifier(bootstrap=True, class_we...                  0.333738   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...                  0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...                  0.307571   \n",
       "RandomForestClassifier(bootstrap=True, class_we...                  0.334204   \n",
       "\n",
       "                                                    test_percent at 0.3 std  \\\n",
       "RandomForestClassifier(bootstrap=True, class_we...                 0.025804   \n",
       "RandomForestClassifier(bootstrap=True, class_we...                 0.038073   \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...                 0.000000   \n",
       "LogisticRegression(C=10, class_weight='auto', d...                 0.025008   \n",
       "RandomForestClassifier(bootstrap=True, class_we...                 0.038582   \n",
       "\n",
       "                                                                               pickle_file  \n",
       "RandomForestClassifier(bootstrap=True, class_we...  yay_pkls/RandomForestClassifier126.pkl  \n",
       "RandomForestClassifier(bootstrap=True, class_we...  yay_pkls/RandomForestClassifier102.pkl  \n",
       "AdaBoostClassifier(algorithm='SAMME.R', base_es...      yay_pkls/AdaBoostClassifier148.pkl  \n",
       "LogisticRegression(C=10, class_weight='auto', d...       yay_pkls/LogisticRegression29.pkl  \n",
       "RandomForestClassifier(bootstrap=True, class_we...  yay_pkls/RandomForestClassifier107.pkl  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df = evaluation.dict_to_dataframe(eval_dct, pkl_dct)\n",
    "evaluation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can sort the dataframe by a particular metric to see which classifier did the best on that metric. For example, we might be interested in precision at 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_prec_score_mean' 'avg_prec_score_std' 'roc_auc_mean' 'roc_auc_std'\n",
      " 'avg_prec_0.05 mean' 'avg_prec_0.05 std' 'precision at 0.05 mean'\n",
      " 'precision at 0.05 std' 'recall at 0.05 mean' 'recall at 0.05 std'\n",
      " 'test_count at 0.05 mean' 'test_count at 0.05 std'\n",
      " 'test_percent at 0.05 mean' 'test_percent at 0.05 std' 'avg_prec_0.1 mean'\n",
      " 'avg_prec_0.1 std' 'precision at 0.1 mean' 'precision at 0.1 std'\n",
      " 'recall at 0.1 mean' 'recall at 0.1 std' 'test_count at 0.1 mean'\n",
      " 'test_count at 0.1 std' 'test_percent at 0.1 mean'\n",
      " 'test_percent at 0.1 std' 'avg_prec_0.15 mean' 'avg_prec_0.15 std'\n",
      " 'precision at 0.15 mean' 'precision at 0.15 std' 'recall at 0.15 mean'\n",
      " 'recall at 0.15 std' 'test_count at 0.15 mean' 'test_count at 0.15 std'\n",
      " 'test_percent at 0.15 mean' 'test_percent at 0.15 std' 'avg_prec_0.2 mean'\n",
      " 'avg_prec_0.2 std' 'precision at 0.2 mean' 'precision at 0.2 std'\n",
      " 'recall at 0.2 mean' 'recall at 0.2 std' 'test_count at 0.2 mean'\n",
      " 'test_count at 0.2 std' 'test_percent at 0.2 mean'\n",
      " 'test_percent at 0.2 std' 'avg_prec_0.25 mean' 'avg_prec_0.25 std'\n",
      " 'precision at 0.25 mean' 'precision at 0.25 std' 'recall at 0.25 mean'\n",
      " 'recall at 0.25 std' 'test_count at 0.25 mean' 'test_count at 0.25 std'\n",
      " 'test_percent at 0.25 mean' 'test_percent at 0.25 std' 'avg_prec_0.3 mean'\n",
      " 'avg_prec_0.3 std' 'precision at 0.3 mean' 'precision at 0.3 std'\n",
      " 'recall at 0.3 mean' 'recall at 0.3 std' 'test_count at 0.3 mean'\n",
      " 'test_count at 0.3 std' 'test_percent at 0.3 mean'\n",
      " 'test_percent at 0.3 std' 'pickle_file']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision at 0.1 mean</th>\n",
       "      <th>precision at 0.1 std</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>roc_auc_std</th>\n",
       "      <th>test_percent at 0.1 mean</th>\n",
       "      <th>pickle_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression(C=1, class_weight='auto', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr',\\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0)</th>\n",
       "      <td>0.319557</td>\n",
       "      <td>0.065447</td>\n",
       "      <td>0.594181</td>\n",
       "      <td>0.032089</td>\n",
       "      <td>0.099116</td>\n",
       "      <td>yay_pkls/LogisticRegression9.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr',\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0)</th>\n",
       "      <td>0.318762</td>\n",
       "      <td>0.068244</td>\n",
       "      <td>0.590139</td>\n",
       "      <td>0.032635</td>\n",
       "      <td>0.099116</td>\n",
       "      <td>yay_pkls/LogisticRegression26.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression(C=1, class_weight='auto', dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr',\\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0)</th>\n",
       "      <td>0.317870</td>\n",
       "      <td>0.065527</td>\n",
       "      <td>0.593924</td>\n",
       "      <td>0.033104</td>\n",
       "      <td>0.099581</td>\n",
       "      <td>yay_pkls/LogisticRegression27.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr',\\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0)</th>\n",
       "      <td>0.316662</td>\n",
       "      <td>0.066351</td>\n",
       "      <td>0.592775</td>\n",
       "      <td>0.033538</td>\n",
       "      <td>0.099735</td>\n",
       "      <td>yay_pkls/LogisticRegression8.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\\n          intercept_scaling=1, max_iter=100, multi_class='ovr',\\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\\n          verbose=0)</th>\n",
       "      <td>0.316258</td>\n",
       "      <td>0.068131</td>\n",
       "      <td>0.590239</td>\n",
       "      <td>0.032488</td>\n",
       "      <td>0.098806</td>\n",
       "      <td>yay_pkls/LogisticRegression10.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    precision at 0.1 mean  \\\n",
       "LogisticRegression(C=1, class_weight='auto', du...               0.319557   \n",
       "LogisticRegression(C=1, class_weight=None, dual...               0.318762   \n",
       "LogisticRegression(C=1, class_weight='auto', du...               0.317870   \n",
       "LogisticRegression(C=1, class_weight=None, dual...               0.316662   \n",
       "LogisticRegression(C=10, class_weight=None, dua...               0.316258   \n",
       "\n",
       "                                                    precision at 0.1 std  \\\n",
       "LogisticRegression(C=1, class_weight='auto', du...              0.065447   \n",
       "LogisticRegression(C=1, class_weight=None, dual...              0.068244   \n",
       "LogisticRegression(C=1, class_weight='auto', du...              0.065527   \n",
       "LogisticRegression(C=1, class_weight=None, dual...              0.066351   \n",
       "LogisticRegression(C=10, class_weight=None, dua...              0.068131   \n",
       "\n",
       "                                                    roc_auc_mean  roc_auc_std  \\\n",
       "LogisticRegression(C=1, class_weight='auto', du...      0.594181     0.032089   \n",
       "LogisticRegression(C=1, class_weight=None, dual...      0.590139     0.032635   \n",
       "LogisticRegression(C=1, class_weight='auto', du...      0.593924     0.033104   \n",
       "LogisticRegression(C=1, class_weight=None, dual...      0.592775     0.033538   \n",
       "LogisticRegression(C=10, class_weight=None, dua...      0.590239     0.032488   \n",
       "\n",
       "                                                    test_percent at 0.1 mean  \\\n",
       "LogisticRegression(C=1, class_weight='auto', du...                  0.099116   \n",
       "LogisticRegression(C=1, class_weight=None, dual...                  0.099116   \n",
       "LogisticRegression(C=1, class_weight='auto', du...                  0.099581   \n",
       "LogisticRegression(C=1, class_weight=None, dual...                  0.099735   \n",
       "LogisticRegression(C=10, class_weight=None, dua...                  0.098806   \n",
       "\n",
       "                                                                          pickle_file  \n",
       "LogisticRegression(C=1, class_weight='auto', du...   yay_pkls/LogisticRegression9.pkl  \n",
       "LogisticRegression(C=1, class_weight=None, dual...  yay_pkls/LogisticRegression26.pkl  \n",
       "LogisticRegression(C=1, class_weight='auto', du...  yay_pkls/LogisticRegression27.pkl  \n",
       "LogisticRegression(C=1, class_weight=None, dual...   yay_pkls/LogisticRegression8.pkl  \n",
       "LogisticRegression(C=10, class_weight=None, dua...  yay_pkls/LogisticRegression10.pkl  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print evaluation_df.columns.values\n",
    "sorted_df = evaluation_df.sort('precision at 0.1 mean', ascending=False)\n",
    "sorted_df[['precision at 0.1 mean', 'precision at 0.1 std', 'roc_auc_mean', 'roc_auc_std', 'test_percent at 0.1 mean', 'pickle_file']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to load the best model back into memory, we can do that using `joblib`. This is especially useful when running a model in the backend. That wraps up the `babysaver` module!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='auto', dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "best_clf = joblib.load(sorted_df['pickle_file'][0])\n",
    "best_clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
